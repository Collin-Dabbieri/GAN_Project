Here we're creating a convolutional GAN, basically we're treating the music as an image where the x-axis is time and the y-axis is pitch. This has a few benefits, it allows for uneven spacings in between notes and chords, and it utilizes convolution, which has been shown to work well with GANs. One potential problem is that your image only contains a small amount of time, so the model might have a hard time learning long-term structure. Perhaps we can treat channels as a continuation of the time-domain information. So the first channel has the data for the first X seconds, the second channel contains data from X+1-2X seconds, and so on.