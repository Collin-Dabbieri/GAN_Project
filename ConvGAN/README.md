Here we're creating a convolutional GAN, basically we're treating the music as an image where the x-axis is time and the y-axis is pitch. This has a few benefits, it allows for uneven spacings in between notes and chords, and it utilizes image convolution, which has been shown to work well with GANs. One potential problem is that your image only contains a small amount of time, so the model might have a hard time learning long-term structure. Perhaps we can treat channels as a continuation of the time-domain information. So the first channel has the data for the first measure, the second channel contains data from the second measure, and so on. To increase the amount of training data we can stride by one, so the first sample has measures 1,2,3,4, the second sample has measures 2,3,4,5, and so on.